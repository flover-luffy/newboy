package net.luffy.util.summary.nlp;

import net.luffy.util.UnifiedLogger;
import java.util.*;

/**
 * NLPç®—æ³•æµ‹è¯•è¿è¡Œå™¨
 * ç”¨äºæµ‹è¯•å’ŒéªŒè¯TF-IDFå’Œå¢å¼ºæƒ…æ„Ÿåˆ†æç®—æ³•çš„æ•ˆæœ
 * 
 * @author Luffy
 * @since 2024-01-20
 */
public class NlpTestRunner {
    
    private final UnifiedLogger logger = UnifiedLogger.getInstance();
    private final TfIdfAnalyzer tfIdfAnalyzer;
    private final EnhancedSentimentAnalyzer sentimentAnalyzer;
    
    // æµ‹è¯•ç”¨çš„åœç”¨è¯
    private static final Set<String> TEST_STOP_WORDS = Set.of(
        "çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸ª", "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°", "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "è¿™", "é‚£", "ä»€ä¹ˆ", "å¯ä»¥", "è¿™ä¸ª", "è¿˜", "æ¯”"
    );
    
    public NlpTestRunner() {
        this.tfIdfAnalyzer = new TfIdfAnalyzer(TEST_STOP_WORDS);
        this.sentimentAnalyzer = new EnhancedSentimentAnalyzer();
    }
    
    /**
     * è¿è¡Œæ‰€æœ‰æµ‹è¯•
     */
    public void runAllTests() {
        logger.info("NlpTestRunner", "å¼€å§‹è¿è¡ŒNLPç®—æ³•æµ‹è¯•...");
        
        testTfIdfAnalyzer();
        testSentimentAnalyzer();
        testIntegratedAnalysis();
        
        logger.info("NlpTestRunner", "NLPç®—æ³•æµ‹è¯•å®Œæˆï¼");
    }
    
    /**
     * æµ‹è¯•TF-IDFç®—æ³•
     */
    public void testTfIdfAnalyzer() {
        logger.info("NlpTestRunner", "=== TF-IDFç®—æ³•æµ‹è¯• ===");
        
        // å‡†å¤‡æµ‹è¯•æ–‡æ¡£
        Map<String, String> testDocuments = new HashMap<>();
        testDocuments.put("doc1", "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆå‡ºå»ç©ã€‚å¤§å®¶éƒ½å¾ˆå¼€å¿ƒï¼Œå¿ƒæƒ…ç‰¹åˆ«å¥½ã€‚");
        testDocuments.put("doc2", "æ˜¨å¤©ä¸‹é›¨äº†ï¼Œå¿ƒæƒ…æœ‰ç‚¹éƒé—·ã€‚ä¸è¿‡é›¨åçš„ç©ºæ°”å¾ˆæ¸…æ–°ï¼Œè¿˜æ˜¯æŒºä¸é”™çš„ã€‚");
        testDocuments.put("doc3", "æœ€è¿‘å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œæ„Ÿè§‰å¾ˆç´¯ã€‚å¸Œæœ›èƒ½å¤Ÿæ”¾æ¾ä¸€ä¸‹ï¼Œå»æ—…æ¸¸æ•£æ•£å¿ƒã€‚");
        testDocuments.put("doc4", "æ–°çš„é¡¹ç›®è¿›å±•é¡ºåˆ©ï¼Œå›¢é˜Ÿåˆä½œå¾ˆå¥½ã€‚å¤§å®¶éƒ½å¾ˆåŠªåŠ›ï¼Œç›¸ä¿¡ä¼šæœ‰å¥½ç»“æœã€‚");
        testDocuments.put("doc5", "ä»Šå¤©çœ‹äº†ä¸€éƒ¨ç”µå½±ï¼Œå‰§æƒ…å¾ˆç²¾å½©ã€‚æ¼”å‘˜æ¼”æŠ€ä¹Ÿå¾ˆæ£’ï¼Œæ¨èå¤§å®¶å»çœ‹ã€‚");
        
        // æ·»åŠ æ–‡æ¡£åˆ°åˆ†æå™¨
        tfIdfAnalyzer.clear();
        tfIdfAnalyzer.addDocuments(testDocuments);
        
        // è·å–è¯­æ–™åº“ç»Ÿè®¡ä¿¡æ¯
        TfIdfAnalyzer.CorpusStats stats = tfIdfAnalyzer.getCorpusStats();
        logger.info("NlpTestRunner", "è¯­æ–™åº“ç»Ÿè®¡: " + stats.toString());
        
        // è·å–å…¨å±€å…³é”®è¯
        List<TfIdfAnalyzer.KeywordScore> globalKeywords = tfIdfAnalyzer.getTopKeywords(10);
        logger.info("NlpTestRunner", "å…¨å±€å…³é”®è¯ (TF-IDF):");
        for (TfIdfAnalyzer.KeywordScore keyword : globalKeywords) {
            logger.info("NlpTestRunner", "  " + keyword.toString());
        }
        
        // æµ‹è¯•å•ä¸ªæ–‡æ¡£çš„å…³é”®è¯
        logger.info("NlpTestRunner", "æ–‡æ¡£1å…³é”®è¯:");
        List<TfIdfAnalyzer.KeywordScore> doc1Keywords = tfIdfAnalyzer.getDocumentKeywords("doc1", 5);
        for (TfIdfAnalyzer.KeywordScore keyword : doc1Keywords) {
            logger.info("NlpTestRunner", "  " + keyword.toString());
        }
        
        // æµ‹è¯•æ–‡æ¡£ç›¸ä¼¼åº¦
        double similarity12 = tfIdfAnalyzer.calculateCosineSimilarity("doc1", "doc2");
        double similarity14 = tfIdfAnalyzer.calculateCosineSimilarity("doc1", "doc4");
        logger.info("NlpTestRunner", String.format("æ–‡æ¡£1ä¸æ–‡æ¡£2ç›¸ä¼¼åº¦: %.4f", similarity12));
        logger.info("NlpTestRunner", String.format("æ–‡æ¡£1ä¸æ–‡æ¡£4ç›¸ä¼¼åº¦: %.4f", similarity14));
        
        logger.info("NlpTestRunner", "TF-IDFç®—æ³•æµ‹è¯•å®Œæˆ\n");
    }
    
    /**
     * æµ‹è¯•å¢å¼ºæƒ…æ„Ÿåˆ†æç®—æ³•
     */
    public void testSentimentAnalyzer() {
        logger.info("NlpTestRunner", "=== å¢å¼ºæƒ…æ„Ÿåˆ†æç®—æ³•æµ‹è¯• ===");
        
        // å‡†å¤‡æµ‹è¯•æ–‡æœ¬
        String[] testTexts = {
            "ä»Šå¤©å¿ƒæƒ…éå¸¸å¥½ï¼é˜³å…‰æ˜åªšï¼Œä¸€åˆ‡éƒ½å¾ˆå®Œç¾ğŸ˜Š",
            "å·¥ä½œå‹åŠ›å¤ªå¤§äº†ï¼Œæ„Ÿè§‰å¾ˆç´¯å¾ˆçƒ¦èºğŸ˜",
            "è¿™ä¸ªç”µå½±è¶…çº§æ£’ï¼æ¼”æŠ€å¾ˆå‰å®³ï¼Œå‰§æƒ…ä¹Ÿå¾ˆç²¾å½©ğŸ‘",
            "å¤©æ°”ä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„æ„Ÿè§‰",
            "ä¸æ˜¯å¾ˆå–œæ¬¢è¿™ä¸ªè®¾è®¡ï¼Œæ„Ÿè§‰æœ‰ç‚¹æ™®é€š",
            "å“‡ï¼è¿™ä¸ªæ¶ˆæ¯å¤ªéœ‡æ’¼äº†ï¼å®Œå…¨æ²¡æƒ³åˆ°ä¼šè¿™æ ·ï¼ï¼ï¼",
            "è¿˜è¡Œå§ï¼Œå‡‘åˆèƒ½ç”¨ï¼Œä¸ç®—å¤ªå·®",
            "ç»å¯¹ä¸æ¨èï¼è´¨é‡å¤ªç³Ÿç³•äº†ï¼Œå®Œå…¨æ˜¯æµªè´¹é’±ğŸ’”"
        };
        
        for (int i = 0; i < testTexts.length; i++) {
            String text = testTexts[i];
            EnhancedSentimentAnalyzer.SentimentResult result = sentimentAnalyzer.analyzeSentiment(text);
            
            logger.info("NlpTestRunner", String.format("æ–‡æœ¬%d: %s", i + 1, text));
            logger.info("NlpTestRunner", String.format("  æƒ…æ„Ÿåˆ†æ: %s", result.getSentimentDescription()));
            logger.info("NlpTestRunner", String.format("  æƒ…æ„Ÿè¯æ±‡: %s", result.getEmotionWords()));
            
            // æ˜¾ç¤ºå¥å­çº§åˆ«åˆ†æ
            if (result.sentences.size() > 1) {
                logger.info("NlpTestRunner", "  å¥å­åˆ†æ:");
                for (EnhancedSentimentAnalyzer.SentenceAnalysis sentence : result.sentences) {
                    logger.info("NlpTestRunner", String.format("    \"%s\" -> %.2f", 
                            sentence.sentence, sentence.sentimentScore));
                }
            }
            logger.info("NlpTestRunner", "");
        }
        
        // æ‰¹é‡åˆ†ææµ‹è¯•
        Map<String, String> batchTexts = new HashMap<>();
        for (int i = 0; i < testTexts.length; i++) {
            batchTexts.put("text_" + (i + 1), testTexts[i]);
        }
        
        Map<String, EnhancedSentimentAnalyzer.SentimentResult> batchResults = 
                sentimentAnalyzer.batchAnalyze(batchTexts);
        
        logger.info("NlpTestRunner", "æ‰¹é‡åˆ†æç»“æœç»Ÿè®¡:");
        Map<EnhancedSentimentAnalyzer.SentimentType, Integer> typeCount = new HashMap<>();
        double totalScore = 0.0;
        
        for (EnhancedSentimentAnalyzer.SentimentResult result : batchResults.values()) {
            typeCount.merge(result.sentimentType, 1, Integer::sum);
            totalScore += result.sentimentScore;
        }
        
        for (Map.Entry<EnhancedSentimentAnalyzer.SentimentType, Integer> entry : typeCount.entrySet()) {
            logger.info("NlpTestRunner", String.format("  %s: %dæ¡", 
                    entry.getKey().getDescription(), entry.getValue()));
        }
        logger.info("NlpTestRunner", String.format("  å¹³å‡æƒ…æ„Ÿå¾—åˆ†: %.2f", totalScore / batchResults.size()));
        
        logger.info("NlpTestRunner", "å¢å¼ºæƒ…æ„Ÿåˆ†æç®—æ³•æµ‹è¯•å®Œæˆ\n");
    }
    
    /**
     * æµ‹è¯•é›†æˆåˆ†æ
     */
    public void testIntegratedAnalysis() {
        logger.info("NlpTestRunner", "=== é›†æˆåˆ†ææµ‹è¯• ===");
        
        // æ¨¡æ‹Ÿæˆ¿é—´æ¶ˆæ¯æ•°æ®
        List<String> roomMessages = Arrays.asList(
            "æ—©ä¸Šå¥½å¤§å®¶ï¼ä»Šå¤©å¤©æ°”çœŸä¸é”™ğŸ˜Š",
            "æ˜¨å¤©çš„ç›´æ’­å¤ªç²¾å½©äº†ï¼æ„Ÿè°¢å°å§å§çš„ç²¾å½©è¡¨æ¼”ğŸ‘",
            "å·¥ä½œå¥½ç´¯å•Šï¼Œå¸Œæœ›èƒ½æ—©ç‚¹ä¸‹ç­",
            "è¿™ä¸ªæ–°æ­ŒçœŸçš„å¾ˆå¥½å¬ï¼Œå¾ªç¯æ’­æ”¾ä¸­ğŸµ",
            "æœ‰ç‚¹æƒ³å®¶äº†ï¼Œå¥½ä¹…æ²¡å›å»çœ‹çœ‹äº†",
            "ä»Šå¤©å¿ƒæƒ…ç‰¹åˆ«å¥½ï¼Œä»€ä¹ˆéƒ½å¾ˆé¡ºåˆ©âœ¨",
            "è¿™ä¸ªæ´»åŠ¨å®‰æ’å¾—å¾ˆæ£’ï¼ŒæœŸå¾…ä¸‹æ¬¡",
            "å¤©æ°”é¢„æŠ¥è¯´æ˜å¤©è¦ä¸‹é›¨ï¼Œè®°å¾—å¸¦ä¼",
            "æ–°çš„å‘¨è¾¹è®¾è®¡å¾ˆå¯çˆ±ï¼Œå·²ç»ä¸‹å•äº†ğŸ’•",
            "æœ€è¿‘å‹åŠ›æœ‰ç‚¹å¤§ï¼Œéœ€è¦æ”¾æ¾ä¸€ä¸‹"
        );
        
        // TF-IDFå…³é”®è¯åˆ†æ
        tfIdfAnalyzer.clear();
        Map<String, String> messageMap = new HashMap<>();
        for (int i = 0; i < roomMessages.size(); i++) {
            messageMap.put("msg_" + i, roomMessages.get(i));
        }
        tfIdfAnalyzer.addDocuments(messageMap);
        
        List<TfIdfAnalyzer.KeywordScore> keywords = tfIdfAnalyzer.getTopKeywords(8);
        logger.info("NlpTestRunner", "æˆ¿é—´æ¶ˆæ¯å…³é”®è¯åˆ†æ:");
        for (TfIdfAnalyzer.KeywordScore keyword : keywords) {
            logger.info("NlpTestRunner", "  " + keyword.toString());
        }
        
        // æ•´ä½“æƒ…æ„Ÿåˆ†æ
        String combinedText = String.join(" ", roomMessages);
        EnhancedSentimentAnalyzer.SentimentResult overallSentiment = 
                sentimentAnalyzer.analyzeSentiment(combinedText);
        
        logger.info("NlpTestRunner", "æˆ¿é—´æ•´ä½“æƒ…æ„Ÿåˆ†æ:");
        logger.info("NlpTestRunner", "  " + overallSentiment.getSentimentDescription());
        logger.info("NlpTestRunner", "  ä¸»è¦æƒ…æ„Ÿè¯æ±‡: " + overallSentiment.getEmotionWords());
        
        // æ¶ˆæ¯æƒ…æ„Ÿåˆ†å¸ƒ
        Map<EnhancedSentimentAnalyzer.SentimentType, Integer> sentimentDistribution = new HashMap<>();
        double totalSentimentScore = 0.0;
        
        for (String message : roomMessages) {
            EnhancedSentimentAnalyzer.SentimentResult result = sentimentAnalyzer.analyzeSentiment(message);
            sentimentDistribution.merge(result.sentimentType, 1, Integer::sum);
            totalSentimentScore += result.sentimentScore;
        }
        
        logger.info("NlpTestRunner", "æ¶ˆæ¯æƒ…æ„Ÿåˆ†å¸ƒ:");
        for (Map.Entry<EnhancedSentimentAnalyzer.SentimentType, Integer> entry : sentimentDistribution.entrySet()) {
            double percentage = (double) entry.getValue() / roomMessages.size() * 100;
            logger.info("NlpTestRunner", String.format("  %s: %dæ¡ (%.1f%%)", 
                    entry.getKey().getDescription(), entry.getValue(), percentage));
        }
        
        logger.info("NlpTestRunner", String.format("å¹³å‡æƒ…æ„Ÿå¾—åˆ†: %.2f", totalSentimentScore / roomMessages.size()));
        
        logger.info("NlpTestRunner", "é›†æˆåˆ†ææµ‹è¯•å®Œæˆ\n");
    }
    
    /**
     * æ€§èƒ½æµ‹è¯•
     */
    public void performanceTest() {
        logger.info("NlpTestRunner", "=== æ€§èƒ½æµ‹è¯• ===");
        
        // ç”Ÿæˆå¤§é‡æµ‹è¯•æ•°æ®
        List<String> largeDataset = new ArrayList<>();
        String[] templates = {
            "ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼Œå¤©æ°”ä¹Ÿä¸é”™",
            "å·¥ä½œæœ‰ç‚¹ç´¯ï¼Œä½†æ˜¯å¾ˆå……å®",
            "è¿™ä¸ªæ´»åŠ¨å¾ˆæœ‰è¶£ï¼Œå¤§å®¶éƒ½å¾ˆå¼€å¿ƒ",
            "æœ€è¿‘å‹åŠ›æ¯”è¾ƒå¤§ï¼Œéœ€è¦è°ƒæ•´ä¸€ä¸‹",
            "æ–°çš„é¡¹ç›®è¿›å±•é¡ºåˆ©ï¼Œå›¢é˜Ÿåˆä½œå¾ˆå¥½"
        };
        
        for (int i = 0; i < 1000; i++) {
            largeDataset.add(templates[i % templates.length] + " " + i);
        }
        
        // TF-IDFæ€§èƒ½æµ‹è¯•
        long startTime = System.currentTimeMillis();
        tfIdfAnalyzer.clear();
        Map<String, String> largeDocuments = new HashMap<>();
        for (int i = 0; i < largeDataset.size(); i++) {
            largeDocuments.put("doc_" + i, largeDataset.get(i));
        }
        tfIdfAnalyzer.addDocuments(largeDocuments);
        List<TfIdfAnalyzer.KeywordScore> perfKeywords = tfIdfAnalyzer.getTopKeywords(20);
        long tfIdfTime = System.currentTimeMillis() - startTime;
        
        logger.info("NlpTestRunner", String.format("TF-IDFå¤„ç†%dæ¡æ–‡æ¡£è€—æ—¶: %dæ¯«ç§’", 
                largeDataset.size(), tfIdfTime));
        
        // æƒ…æ„Ÿåˆ†ææ€§èƒ½æµ‹è¯•
        startTime = System.currentTimeMillis();
        Map<String, String> sentimentTexts = new HashMap<>();
        for (int i = 0; i < Math.min(100, largeDataset.size()); i++) {
            sentimentTexts.put("text_" + i, largeDataset.get(i));
        }
        Map<String, EnhancedSentimentAnalyzer.SentimentResult> perfSentiments = 
                sentimentAnalyzer.batchAnalyze(sentimentTexts);
        long sentimentTime = System.currentTimeMillis() - startTime;
        
        logger.info("NlpTestRunner", String.format("æƒ…æ„Ÿåˆ†æå¤„ç†%dæ¡æ–‡æœ¬è€—æ—¶: %dæ¯«ç§’", 
                sentimentTexts.size(), sentimentTime));
        
        logger.info("NlpTestRunner", "æ€§èƒ½æµ‹è¯•å®Œæˆ\n");
    }
    
    /**
     * ä¸»æµ‹è¯•æ–¹æ³•
     */
    public static void main(String[] args) {
        NlpTestRunner testRunner = new NlpTestRunner();
        testRunner.runAllTests();
        testRunner.performanceTest();
    }
}